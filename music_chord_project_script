
# 1. Define libraries

import urllib
import bs4
import re
import datetime
import string

# 2. get the URL

sementara_sendiri = urllib.request.urlopen("https://tabs.ultimate-guitar.com/g/geisha/sementara_sendiri_crd.htm")

from urllib.request import urlopen
sementara_sendiri_3 = urlopen("https://tabs.ultimate-guitar.com/g/geisha/sementara_sendiri_crd.htm") 
print(sementara_sendiri_3)

# 3. select the relevant stuff from it with beautiful soup

soup = bs4.BeautifulSoup(sementara_sendiri_3)

print(soup.prettify()) # look at nested structure of html

# 4. get the body (chords and lyrics) that are in tag <tb_ct>

# tb_ct_content = soup.find_all("pre", {"class":"js-tab-content js-copy-content js-tab-controls-item"}) # apparently this doesnt work anymore, try below code (30.08.2017)
tb_ct_content = soup.find_all("pre", {"class":"js-tab-content js-init-edit-form js-copy-content js-tab-controls-item"}) # distills the important stuff better


tb_ct_content_string = str(tb_ct_content)

# 5. isolate the chords

chord_list = re.findall('<span>(.*)</span>', tb_ct_content_string)
chord_list_2 = [re.sub("<span>", "", line) for line in chord_list]
chord_list_3 = [re.sub("</span>", "", line) for line in chord_list_2]



# Looping thorugh all of the songs --> For that one needs three nested loops
# WRONG: Get all the page names by crawling thorugh the 

# for i in {A-Z} https://www.ultimate-guitar.com/bands/{i}.htm



# 6. Get a list with all artists out there

from urllib.request import urlopen
d={} # create an empty dictionary
for letter in string.ascii_lowercase: # string.ascii_lowercase gives you all lower case letters in the alphabet
    d["artist_page_" + letter] = [] # You are creating a dictionary with key {artist_page_<laufvariable>: NULL}, e.g. artist_page_a, artist_page_b
    print("We are at letter:" + letter)
    for page_count in range(1,3): # for every artist_page_<letter> you are opening up artist_page_<letter>_<page_number> and perform operations
        #a_artists_page = urlopen("https://www.ultimate-guitar.com/bands/a"+str(page_count)+".htm")
        d["artist_page_" + letter] = urlopen("https://www.ultimate-guitar.com/bands/a"+str(page_count)+".htm")
        
        soup = bs4.BeautifulSoup(a_artists_page) # get file    
        artist_list = soup.find_all("tr", {"class":"tr"}) # Extract the relevant part
        artist_list_raw = soup.find_all("td", {"style":"color:#DDDDCC"}) # within the part try to only get the links --> All of them all in color:#DDD.. style
        artist_list_raw_str = str(artist_list_raw) # convert to string to substring stuff --> It splits elemtns by <space>
        artist_list_raw_list = artist_list_raw_str.split() # split up the string into a list of substrings
        
        from fnmatch import fnmatch, fnmatchcase
        artist_list_temp = [x for x in artist_list_raw_list if fnmatch(x, "href=*")]
        artist_list_temp_2 = [re.sub("href=\"", "", line) for line in artist_list_temp]
        artist_list_temp_3 = [re.sub("\">A", "", line) for line in artist_list_temp_2]
        artist_list_a.append(artist_list_temp_3)
        print(str(datetime.datetime.now()) + "Within letter " + letter + " this is page number: + str(page_count))
